{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "360e54052a5042c09cd97a866cc83a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7bf5726ba464ff1883980a0615fbded",
              "IPY_MODEL_69bf94f508ea4694822221b18e61704d",
              "IPY_MODEL_9a2990cdba84407e8c4f1c15907d9fa6"
            ],
            "layout": "IPY_MODEL_f8e9144d1a9b4cc7abe1e11c4715884e"
          }
        },
        "f7bf5726ba464ff1883980a0615fbded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce4d5debfa946089626061459739eed",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c98853265d4b838c0481932f8639a3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "69bf94f508ea4694822221b18e61704d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7f5dfd525c47c48a6eab6b9d93fd90",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6355c555e21b4138bf210c031ab9c02f",
            "value": 2
          }
        },
        "9a2990cdba84407e8c4f1c15907d9fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1386039194174a7a9f2de1ddd8f130c0",
            "placeholder": "​",
            "style": "IPY_MODEL_b4784241d00547b0ac306cfe65765165",
            "value": " 2/2 [00:31&lt;00:00, 13.57s/it]"
          }
        },
        "f8e9144d1a9b4cc7abe1e11c4715884e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce4d5debfa946089626061459739eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c98853265d4b838c0481932f8639a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa7f5dfd525c47c48a6eab6b9d93fd90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6355c555e21b4138bf210c031ab9c02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1386039194174a7a9f2de1ddd8f130c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4784241d00547b0ac306cfe65765165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e96c1351c6e41d5ae5c9747e707b289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_162b1996fbe64d24b714bc7e63335535",
              "IPY_MODEL_fef86e8c75724a94926db9b1242b60b5",
              "IPY_MODEL_df211647e5124a04b3a8b1b3d04bb91c"
            ],
            "layout": "IPY_MODEL_88fb9aa040c14a5481aae4663cca0393"
          }
        },
        "162b1996fbe64d24b714bc7e63335535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efebb1b6ea4a4846a77c52f511402c61",
            "placeholder": "​",
            "style": "IPY_MODEL_11183fd2bcb04df59da2875da6797ad0",
            "value": "Generating train split: "
          }
        },
        "fef86e8c75724a94926db9b1242b60b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef91530e6af45d8984f40efc132f440",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00ec22bdb6bd43f086c811b6465f56f2",
            "value": 1
          }
        },
        "df211647e5124a04b3a8b1b3d04bb91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3698bde32d2540649a6ced39514b12de",
            "placeholder": "​",
            "style": "IPY_MODEL_88e0e7580b5f4ae68c581c440a4b2a30",
            "value": " 1000/0 [00:00&lt;00:00, 9192.39 examples/s]"
          }
        },
        "88fb9aa040c14a5481aae4663cca0393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efebb1b6ea4a4846a77c52f511402c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11183fd2bcb04df59da2875da6797ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef91530e6af45d8984f40efc132f440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "00ec22bdb6bd43f086c811b6465f56f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3698bde32d2540649a6ced39514b12de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e0e7580b5f4ae68c581c440a4b2a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7ef18cbc8bd4b35af64ee916dda8556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d9d923c3bd04a669169d89b26ac8c8c",
              "IPY_MODEL_8b246e3a2c2d4f43a065e83675fb4bb0",
              "IPY_MODEL_afa4fb76dd104f51b6054501a8bb5d80"
            ],
            "layout": "IPY_MODEL_a9494d0e119446d7a44d73551a6010b4"
          }
        },
        "0d9d923c3bd04a669169d89b26ac8c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5dc87ba24e448ec9fdc43c82dd8c09c",
            "placeholder": "​",
            "style": "IPY_MODEL_959f8c0c57754721b91a6851ff284f68",
            "value": "Map: 100%"
          }
        },
        "8b246e3a2c2d4f43a065e83675fb4bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a66f4f1b46420391a8d7565ebc7c38",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdeb2e8787514a8d8b9f43524e4209f5",
            "value": 1000
          }
        },
        "afa4fb76dd104f51b6054501a8bb5d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ce7dafc3a49496c8f730e101c0d0385",
            "placeholder": "​",
            "style": "IPY_MODEL_b6136fee75be45a2b45655b046f1be9d",
            "value": " 1000/1000 [00:03&lt;00:00, 333.41 examples/s]"
          }
        },
        "a9494d0e119446d7a44d73551a6010b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5dc87ba24e448ec9fdc43c82dd8c09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959f8c0c57754721b91a6851ff284f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a66f4f1b46420391a8d7565ebc7c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdeb2e8787514a8d8b9f43524e4209f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ce7dafc3a49496c8f730e101c0d0385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6136fee75be45a2b45655b046f1be9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b25d4f1de4e492d8284c2e20213d0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12b96140456540e8967b8305b1191a35",
              "IPY_MODEL_dd0db811870c430a973d504a72448a29",
              "IPY_MODEL_34b2dde48d36494a82a9d97287148f55"
            ],
            "layout": "IPY_MODEL_ffd9fdf5f5ae4fbd9510ea2994f23bb7"
          }
        },
        "12b96140456540e8967b8305b1191a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c2d5fecc364d3e8bdf8f2fa14dac36",
            "placeholder": "​",
            "style": "IPY_MODEL_5de61e5259d54a769dab6188e117808d",
            "value": "Map: 100%"
          }
        },
        "dd0db811870c430a973d504a72448a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5270b9fc8d04e1bac40a96d6d3eb00e",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aa12fc65a1a49d4b9b128d22f8cc50d",
            "value": 1000
          }
        },
        "34b2dde48d36494a82a9d97287148f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f79a8d0aaa44e0b44ddb2c9c407059",
            "placeholder": "​",
            "style": "IPY_MODEL_ed4aeafce5ea498f9a466cccc61835c5",
            "value": " 1000/1000 [00:15&lt;00:00, 82.11 examples/s]"
          }
        },
        "ffd9fdf5f5ae4fbd9510ea2994f23bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c2d5fecc364d3e8bdf8f2fa14dac36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de61e5259d54a769dab6188e117808d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5270b9fc8d04e1bac40a96d6d3eb00e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa12fc65a1a49d4b9b128d22f8cc50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59f79a8d0aaa44e0b44ddb2c9c407059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4aeafce5ea498f9a466cccc61835c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq bitsandbytes\n",
        "!pip install -Uq accelerate optimum\n",
        "!pip install -Uq transformers\n",
        "!pip install -Uq peft\n",
        "!pip install -Uq trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84n4_q1cFPbY",
        "outputId": "8c00b235-6be0-4b25-992d-117511e97483"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.1/407.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kDBJ0aXgFG09"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import bitsandbytes\n",
        "#import accelerate\n",
        "import transformers\n",
        "import optimum\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import (\n",
        "    get_peft_model,\n",
        "    LoraConfig,\n",
        "    TaskType,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from trl import DPOTrainer\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import os"
      ],
      "metadata": {
        "id": "1OcBR1VvGVZw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment/Uncomment and use as per wish\n",
        "# MODEL_PATH = \"/kaggle/input/gemma/pytorch/2b-it/2\" # \"/kaggle/input/gemma/pytorch/2b-it/2\" \"/kaggle/input/gemma/transformers/2b-it/2\"\n",
        "# MODEL_PATH = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
        "\n",
        "MODEL_PATH = \"/kaggle/input/phi/transformers/2/1\"\n",
        "\n",
        "\n",
        "torch.set_default_device(\"cuda\")\n",
        "\n",
        "#model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT_gFU1sFxbi",
        "outputId": "d8d6c0b2-8fb6-45bb-90fa-1c5aaaefaa70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the training dataset\n",
        "#dataset = load_dataset(\"json\", data_files={'train': dataset_file})\n",
        "dataset = pd.read_csv(\"/content/dpo_dataset_v1.csv\")\n",
        "#dataset = dataset['train'].shuffle(seed=42)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "device_map = \"auto\"\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "base_model.config.use_cache = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "360e54052a5042c09cd97a866cc83a85",
            "f7bf5726ba464ff1883980a0615fbded",
            "69bf94f508ea4694822221b18e61704d",
            "9a2990cdba84407e8c4f1c15907d9fa6",
            "f8e9144d1a9b4cc7abe1e11c4715884e",
            "5ce4d5debfa946089626061459739eed",
            "b3c98853265d4b838c0481932f8639a3",
            "fa7f5dfd525c47c48a6eab6b9d93fd90",
            "6355c555e21b4138bf210c031ab9c02f",
            "1386039194174a7a9f2de1ddd8f130c0",
            "b4784241d00547b0ac306cfe65765165"
          ]
        },
        "id": "m-uolcuqFxZU",
        "outputId": "eedce277-2aa4-478c-e827-53f1ab197a32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "360e54052a5042c09cd97a866cc83a85"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "idVW5OJGOpNx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "LjKrV4sNFOwi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/dpo_dataset_v1.csv\", index_col=0)\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "qaOmFSdII1Zo",
        "outputId": "fc18fa6f-65f8-4065-e89d-ea1e02c90c42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       original_text  \\\n",
              "0  The task you have given me is quite complex an...   \n",
              "1  The philosophy of happiness is a branch of phi...   \n",
              "2  The impact of technology on the socio-cultural...   \n",
              "3  Title: Debating the Moral and Legal Complexiti...   \n",
              "4  Predicting the future of social justice in mod...   \n",
              "\n",
              "                                      rewritten_text  \\\n",
              "0  ## Analysis of the Text\\n\\nThis text explores ...   \n",
              "1  ## Analysis of the Text: \"The Philosophy of Ha...   \n",
              "2  ## The Whimsical Text with Special Characters ...   \n",
              "3  **Summary:**\\n\\nCognitive dissonance, a psycho...   \n",
              "4  ## Analysis of the Text\\n\\nThis text provides ...   \n",
              "\n",
              "                                       chosen_prompt  \\\n",
              "0  Engage in a thoughtful exploration of the cont...   \n",
              "1  Immerse yourself in a detailed analysis of the...   \n",
              "2  Add a touch of whimsy to the following text by...   \n",
              "3  Capture the essence of the following text in a...   \n",
              "4  Navigate through the maze of contrasting opini...   \n",
              "\n",
              "                                     rejected_prompt  chosen_score  \\\n",
              "0  ## Most Accurate Prompt:\\n\\nWrite an analysis ...             1   \n",
              "1  ## Prompt used to convert the original text to...             1   \n",
              "2  ## Most Accurate Prompt:\\n\\nWrite a transforme...             1   \n",
              "3  The prompt used to convert the original text t...             1   \n",
              "4  **Prompt:** Write an analysis of the text \"Pre...             1   \n",
              "\n",
              "   rejected_score  \n",
              "0               0  \n",
              "1               0  \n",
              "2               0  \n",
              "3               0  \n",
              "4               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22ef6c91-51c5-4418-8fc4-23e2b45df936\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>rewritten_text</th>\n",
              "      <th>chosen_prompt</th>\n",
              "      <th>rejected_prompt</th>\n",
              "      <th>chosen_score</th>\n",
              "      <th>rejected_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The task you have given me is quite complex an...</td>\n",
              "      <td>## Analysis of the Text\\n\\nThis text explores ...</td>\n",
              "      <td>Engage in a thoughtful exploration of the cont...</td>\n",
              "      <td>## Most Accurate Prompt:\\n\\nWrite an analysis ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The philosophy of happiness is a branch of phi...</td>\n",
              "      <td>## Analysis of the Text: \"The Philosophy of Ha...</td>\n",
              "      <td>Immerse yourself in a detailed analysis of the...</td>\n",
              "      <td>## Prompt used to convert the original text to...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The impact of technology on the socio-cultural...</td>\n",
              "      <td>## The Whimsical Text with Special Characters ...</td>\n",
              "      <td>Add a touch of whimsy to the following text by...</td>\n",
              "      <td>## Most Accurate Prompt:\\n\\nWrite a transforme...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Title: Debating the Moral and Legal Complexiti...</td>\n",
              "      <td>**Summary:**\\n\\nCognitive dissonance, a psycho...</td>\n",
              "      <td>Capture the essence of the following text in a...</td>\n",
              "      <td>The prompt used to convert the original text t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Predicting the future of social justice in mod...</td>\n",
              "      <td>## Analysis of the Text\\n\\nThis text provides ...</td>\n",
              "      <td>Navigate through the maze of contrasting opini...</td>\n",
              "      <td>**Prompt:** Write an analysis of the text \"Pre...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22ef6c91-51c5-4418-8fc4-23e2b45df936')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22ef6c91-51c5-4418-8fc4-23e2b45df936 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22ef6c91-51c5-4418-8fc4-23e2b45df936');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d073761e-67af-4769-81ff-8adc76455340\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d073761e-67af-4769-81ff-8adc76455340')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d073761e-67af-4769-81ff-8adc76455340 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"original_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 974,\n        \"samples\": [\n          \"The impact of technology on the evolution of language has been profound and far-reaching. With the advent of new communication tools and platforms, the way we communicate and express ourselves has changed dramatically. Here are some of the key ways in which technology has influenced the evolution of language:\\n\\n1. Text Speak and Emojis: With the rise of text messaging and social media, a new form of language has emerged that is characterized by abbreviations, acronyms, and emojis. This form of communication has become so ubiquitous that it has even been incorporated into formal writing and education.\\n2. Globalization and Multilingualism: Technology has made it easier than ever before to communicate with people from different parts of the world. This has led to the spread of languages and the emergence of new forms of multilingualism. At the same time, it has also created a need for language translation and localization services, which have become a major industry in their own right.\\n3. Language Learning: Technology has also transformed the way we learn languages. With the advent of language learning apps, online courses, and virtual tutoring, it has become easier than ever before to learn a new language. At the same time, technology has also made it possible to connect with language learners from around the world, creating new opportunities for language practice and exchange.\\n4. Language Preservation: Technology has also played a role in preserving endangered languages. With the help of digital tools, linguists and language enthusiasts are able to document and study languages that are at risk of disappearing. This has led to a renewed interest in language preservation and revitalization efforts.\\n5. Artificial Intelligence and Natural Language Processing: Advances in artificial intelligence and natural language processing have made it possible for machines to understand and generate human language. This has led to the development of chatbots, voice assistants, and other applications that can interact with humans in natural language.\\n\\nOverall, technology has had a profound impact on the evolution of language. While it has created new forms of communication and learning, it has also posed new challenges, such as the potential for language loss and the need for language preservation. As technology continues to evolve, it will be interesting to see how it continues to shape the way we communicate and express ourselves.\",\n          \"The portrayal of the evolution of language in media and popular culture is often oversimplified and misrepresented, which can lead to a lack of understanding and appreciation for the complexity and significance of this process.\\n\\nOne common misconception is that language evolved suddenly and simultaneously in multiple locations around the world. However, the majority of linguists believe that language evolved gradually and most likely originated in Africa, where modern humans first appeared.\\n\\nAnother issue is the portrayal of language as a single, unified system. In reality, language is constantly evolving and varies greatly among different communities and regions. This variation is often overlooked in portrayals of language evolution, which can give the impression that language is a static and unchanging entity.\\n\\nAdditionally, the portrayal of the evolution of language as a linear progression, from simple to complex, is also misleading. Language is not a ladder with clear-cut stages, but rather a complex system that has developed and changed over time in response to various social, cultural, and environmental factors.\\n\\nFurthermore, the portrayal of the evolution of language as a solely biological process, driven by genetic adaptation, is also a oversimplification. Language is a complex phenomenon that involves not only biological factors, but also social, cultural and environmental factors.\\n\\nFinally, the portrayal of the evolution of language as a process that only happened in the past is also misleading. Language is still evolving today, and it will continue to evolve in the future.\\n\\nIn conclusion, the portrayal of the evolution of language in media and popular culture often fails to capture the complexity and dynamism of this process. It is important to recognize that language is a complex system that has developed and changed over time in response to various social, cultural, and environmental factors and it is still evolving today.\",\n          \"The Renaissance, which spanned from the 14th to the 17th century, was a period of significant cultural and socio-political change in Europe. This period marked the transition from the Middle Ages to modernity and was characterized by a renewed interest in classical learning and values. The socio-political dynamics and cultural factors that shaped the historical context of the Renaissance period were complex and multifaceted.\\n\\nOne of the key socio-political factors that shaped the Renaissance was the rise of city-states in Italy. The decline of feudalism and the growth of trade and commerce led to the emergence of powerful city-states such as Florence, Venice, and Milan. These city-states were governed by wealthy merchant families who patronized the arts and learning, leading to a flourishing of culture and intellectual activity.\\n\\nThe cultural factors that shaped the Renaissance included the rediscovery of classical Greek and Roman texts and the development of humanism. The rediscovery of classical texts led to a renewed interest in the ideas and values of the ancient world, including the importance of individualism, reason, and scientific inquiry. Humanism, which emphasized the study of the humanities, such as literature, philosophy, and history, further fueled the intellectual and cultural movement of the Renaissance.\\n\\nAnother important cultural factor was the Christian Church's influence. Although the Church initially resisted many of the new ideas and values of the Renaissance, it eventually embraced many of them, leading to a blending of classical and Christian ideas. This synthesis of ideas helped to shape the development of Renaissance art, literature, and philosophy.\\n\\nThe socio-political dynamics of the Renaissance were also shaped by the broader historical context of the time. The period was marked by political instability, wars, and social unrest. The Black Death, which ravaged Europe in the mid-14th century, had a profound impact on European society, leading to a reevaluation of traditional values and beliefs. The rise of the Ottoman Empire and the threat of Islamic expansion also shaped the political landscape of the Renaissance, leading to a sense of urgency and a desire to reclaim the glory of the classical world.\\n\\nIn conclusion, the socio-political dynamics and cultural factors that shaped the historical context of the Renaissance period were complex and multifaceted. The rise of city-states, the rediscovery of classical texts, the development of humanism, the influence of the Church, and the broader historical context of the time all played a role in shaping this transformative period in European history. The Renaissance was a time of great change and upheaval, but it was also a time of great creativity and innovation, laying the groundwork for the modern world.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewritten_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"## Analysis of Text on Cultural Diversity in the Workplace\\n\\nThis text effectively introduces the challenges facing cultural diversity in the workplace and explores various related topics. Here's an analysis of the key points:\\n\\n**Strengths:**\\n\\n* **Clear structure:** The text follows a logical structure, outlining the challenges, discussing their impact, and proposing solutions.\\n* **Comprehensive coverage:** The text covers a wide range of challenges facing cultural diversity in the workplace, including stereotyping, bias, communication issues, lack of representation, and more.\\n* **Balanced perspective:** The text avoids making generalizations or blaming individuals or groups, instead focusing on the need for organizational change and improvement.\\n* **Actionable solutions:** The text provides concrete solutions for addressing the challenges facing cultural diversity in the workplace, such as inclusive hiring practices, cultural competence development, and improved communication.\\n\\n**Areas for Improvement:**\\n\\n* **Lack of citations or references:** The text lacks citations or references to support the claims made about the challenges facing cultural diversity in the workplace. Adding references would lend credibility and allow for further exploration of the topic.\\n* **Overgeneralization:** Some statements in the text might be overly general. For example, stating that \\\"unconscious bias training can be seen as a band-aid solution\\\" might not apply to all organizations.\\n* **Lack of examples:** While the text lists various challenges and solutions, it lacks concrete examples to illustrate the points. Adding specific examples would make the text more relatable and actionable.\\n\\n**Overall:**\\n\\nThis text provides a well-structured and informative overview of the challenges facing cultural diversity in the workplace. It effectively introduces the topic, discusses various challenges, and proposes solutions to create a more inclusive and equitable work environment. With some minor adjustments and the inclusion of references and examples, this text could be even more impactful and informative.\",\n          \"## Summary of Main Themes Explored in the Passage:\\n\\n**1. Organ Scarcity and Commodification:**\\n- The passage highlights the shortage of organs and the potential for organ trafficking and exploitation.\\n- The use of new technologies like 3D printing raises concerns about the commodification of the human body and unequal access to treatments.\\n\\n**2. Ethical Concerns in Organ Donation:**\\n- The organ donation process itself involves coercion and exploitation, particularly in low-income countries.\\n- Financial incentives for organ donation can lead to exploitation and coercion.\\n\\n**3. Allocation Fairness and Equity:**\\n- The allocation of organs is complex and controversial, with concerns about fairness and equity.\\n- Certain groups are less likely to receive transplants, highlighting the need for greater attention to justice and equity.\\n\\n**4. Living Donors and Risks:**\\n- The use of living donors raises concerns about the risks and burdens placed on individuals who donate organs.\\n- The potential exploitation of living donors needs careful consideration.\\n\\n**5. Ethical Considerations in Emerging Technologies:**\\n- The use of new technologies like 3D printing and bioengineering raises ethical concerns about the potential for unequal access and the commodification of human organs.\\n- It is essential to consider the ethical implications of these technologies and ensure that they are used responsibly.\",\n          \"## Contrasting Viewpoint to \\\"Humanizing Technology: Innovative Strategies and Policy Solutions\\\"\\n\\nWhile the passage advocates for a human-centric approach to technology, it primarily focuses on ethical considerations and policy solutions. This viewpoint, while valuable, overlooks the potential benefits and opportunities that technology can offer. Here's a contrasting perspective:\\n\\n**Harnessing Technological Progress:**\\n\\n* **Medical advancements:** Technology has revolutionized healthcare, enabling remote diagnosis, precision medicine, and improved treatment outcomes.\\n* **Enhanced communication:** Communication tools have revolutionized how we connect with each other, bridging geographical barriers and fostering global collaboration.\\n* **Access to information:** The ubiquity of information has democratized knowledge and learning opportunities, empowering individuals with access to vast resources.\\n* **Increased efficiency:** Technological advancements have streamlined processes, improved productivity, and increased efficiency across various industries.\\n\\n**Embracing Technological Opportunities:**\\n\\n* **Economic growth:** The technology sector creates new jobs, drives economic growth, and fosters innovation.\\n* **Educational advancement:** Technology empowers educators to personalize learning, provide access to online resources, and create new learning opportunities.\\n* **Social empowerment:** Technology empowers individuals to connect, express themselves, and access information more easily, fostering social inclusion and empowerment.\\n* **Creative expression:** Technological tools have opened new avenues for creative expression, enabling artists, musicians, and entrepreneurs to reach global audiences.\\n\\n**Addressing Challenges:**\\n\\nIt is important to acknowledge and address the challenges presented by technological advancement, such as cybersecurity threats, data privacy concerns, and potential job displacement. However, these challenges should not overshadow the immense potential for positive change.\\n\\n**Conclusion:**\\n\\nWhile the passage rightly emphasizes the need for ethical considerations and policy solutions, a more comprehensive perspective recognizes the positive impact technology can have on society and individuals. By embracing technological advancements and harnessing their potential, we can create a future where technology empowers humanity to thrive and flourish.\\n\\n**Additional Considerations:**\\n\\n* The passage focuses primarily on Western perspectives and solutions. It would be beneficial to consider how these strategies might translate to different contexts and cultures.\\n* The impact of technology on different demographics and marginalized groups should be carefully considered to ensure equitable access and inclusion.\\n* Ongoing research and innovation are crucial to ensure that technological progress aligns with human needs and aspirations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chosen_prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"Infuse the following passage with personality and charm by incorporating emojis and expressive formatting to convey emotion and tone:\",\n          \"Put a humorous spin on the following passage and entertain us with your witty commentary:\",\n          \"Navigate through the maze of contrasting opinions and perspectives surrounding the concepts introduced in the following passage, illuminating the spectrum of diverse viewpoints and interpretations:\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected_prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 995,\n        \"samples\": [\n          \"The prompt used to convert the original text to the transformed text is:\\n\\n**Write a humorous and engaging narrative about the ethical challenges posed by Artificial Intelligence (AI) and its potential impact on society.**\",\n          \"## Most Accurate Prompt:\\n\\nWrite an analysis of the text \\\"Social Justice is a Concept That Has Evolved Over Time\\\" and discuss its strengths and weaknesses. Include a summary of the text's main points and potential areas for improvement.\",\n          \"**Prompt:** Rewrite the original text in the style of Ernest Hemingway, emphasizing the use of vivid imagery, concise language, and a direct, conversational tone.\\n\\n**Answer:** The prompt used to convert the original text to the transformed text is:\\n\\n**Rewrite the original text in the style of Ernest Hemingway, emphasizing the use of vivid imagery, concise language, and a direct, conversational tone.**\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chosen_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rejected_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content/\""
      ],
      "metadata": {
        "id": "Q-9tRfkbNuf5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `df` is your DataFrame\n",
        "dataset.to_json(\"your_dataset.json\", orient=\"records\", lines=True)\n",
        "\n",
        "# Load the training dataset\n",
        "dataset_file = \"your_dataset.json\"\n",
        "dataset = load_dataset(\"json\", data_files={'train': dataset_file})\n",
        "dataset = dataset['train'].shuffle(seed=42)\n",
        "\n",
        "def truncate_text(example, max_length=900):\n",
        "    # Tokenize the original and rewritten texts to check their length\n",
        "    tokens_original = tokenizer.encode(example['original_text'], add_special_tokens=False)\n",
        "    tokens_rewritten = tokenizer.encode(example['rewritten_text'], add_special_tokens=False)\n",
        "    #print(len(tokens_original), len(tokens_rewritten))\n",
        "\n",
        "    # Check if the length exceeds max_length and truncate if necessary\n",
        "    if len(tokens_original) > max_length:\n",
        "        # Decode back to text after truncating\n",
        "        example['original_text'] = tokenizer.decode(tokens_original[:max_length], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    if len(tokens_rewritten) > max_length:\n",
        "        # Decode back to text after truncating\n",
        "        example['rewritten_text'] = tokenizer.decode(tokens_rewritten[:max_length], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    return example\n",
        "\n",
        "\n",
        "def get_prompt(example):\n",
        "    # Assuming `tokenizer` and other necessary components are defined elsewhere in your notebook\n",
        "    example = truncate_text(example)\n",
        "    #og_text = truncate_text(example['original_text'])\n",
        "    #rewritten_text = truncate_text(example['rewritten_text'])\n",
        "\n",
        "    prompt_sample = [\n",
        "        {\"role\": \"system\", \"content\": \"From the given original and rewritten texts, predict the rewrite prompt used to transform the original text.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Original: {example['original_text']} ----- Rewritten: {example['rewritten_text']} \"}\n",
        "    ]\n",
        "    prompt_for_model = tokenizer.apply_chat_template(prompt_sample, tokenize=False)\n",
        "    example['prompt'] = prompt_for_model\n",
        "\n",
        "    example['chosen'] = example['chosen_prompt'] + tokenizer.eos_token\n",
        "    example['rejected'] = example['rejected_prompt'] + tokenizer.eos_token\n",
        "\n",
        "    return example\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1e96c1351c6e41d5ae5c9747e707b289",
            "162b1996fbe64d24b714bc7e63335535",
            "fef86e8c75724a94926db9b1242b60b5",
            "df211647e5124a04b3a8b1b3d04bb91c",
            "88fb9aa040c14a5481aae4663cca0393",
            "efebb1b6ea4a4846a77c52f511402c61",
            "11183fd2bcb04df59da2875da6797ad0",
            "cef91530e6af45d8984f40efc132f440",
            "00ec22bdb6bd43f086c811b6465f56f2",
            "3698bde32d2540649a6ced39514b12de",
            "88e0e7580b5f4ae68c581c440a4b2a30"
          ]
        },
        "id": "4OC3-2pWNuey",
        "outputId": "23d15fe4-b3a8-4e6f-cef7-95127052dd97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e96c1351c6e41d5ae5c9747e707b289"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the function over the dataset\n",
        "dataset = dataset.map(get_prompt)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "d7ef18cbc8bd4b35af64ee916dda8556",
            "0d9d923c3bd04a669169d89b26ac8c8c",
            "8b246e3a2c2d4f43a065e83675fb4bb0",
            "afa4fb76dd104f51b6054501a8bb5d80",
            "a9494d0e119446d7a44d73551a6010b4",
            "e5dc87ba24e448ec9fdc43c82dd8c09c",
            "959f8c0c57754721b91a6851ff284f68",
            "e6a66f4f1b46420391a8d7565ebc7c38",
            "fdeb2e8787514a8d8b9f43524e4209f5",
            "4ce7dafc3a49496c8f730e101c0d0385",
            "b6136fee75be45a2b45655b046f1be9d"
          ]
        },
        "id": "ph8qH717Ewik",
        "outputId": "6caed234-1271-4512-ded0-c4504aee9d9c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7ef18cbc8bd4b35af64ee916dda8556"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format (without BOS/EOS tokens!). If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['original_text', 'rewritten_text', 'chosen_prompt', 'rejected_prompt', 'chosen_score', 'rejected_score', 'prompt', 'chosen', 'rejected'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.rename_column(\"chosen_score\", \"score_chosen\")\n",
        "dataset = dataset.rename_column(\"rejected_score\", \"score_rejected\")"
      ],
      "metadata": {
        "id": "Q3tEKNXoTM_G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = dataset[0]\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q2zLWIT-gCK",
        "outputId": "f57fab16-8408-4b84-ba5d-39473e5e5aed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'original_text': \"The geopolitical tensions in the Middle East have had significant socio-cultural impacts and far-reaching global ramifications. The region is a hotbed of conflict, with ongoing struggles for power, resources, and political influence. These tensions have resulted in violence, displacement, and instability, which have had profound effects on the people of the region and beyond.\\n\\nOne of the most significant socio-cultural impacts of these tensions is the displacement of millions of people. The conflicts in Syria, Iraq, and Yemen have forced millions of people to flee their homes, creating a massive refugee crisis. Many of these refugees have sought safety in neighboring countries, while others have made the dangerous journey to Europe. This mass displacement has put a significant strain on resources and social services in host countries and has led to cultural and social tensions.\\n\\nThe conflicts in the Middle East have also had a profound impact on the region's cultural heritage. Many historical sites and artifacts have been destroyed or damaged in the fighting, and the region's rich cultural diversity is under threat. The destruction of cultural heritage sites has not only had a devastating impact on the region's cultural identity but has also had economic consequences, as tourism, a significant source of income for many countries in the region, has declined.\\n\\nThe geopolitical tensions in the Middle East have also had significant global ramifications. The region is a major source of oil and gas, and the conflicts have led to disruptions in the global energy market. The rise in oil prices caused by these disruptions has had a ripple effect on the global economy, contributing to inflation and economic instability.\\n\\nFurthermore, the conflicts in the Middle East have had security implications beyond the region. The rise of extremist groups such as ISIS and their spread beyond the region has posed a threat to global security. The conflicts have also led to the proliferation of weapons, including weapons of mass destruction, which poses a significant threat to international peace and security.\\n\\nIn conclusion, the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East are significant and far-reaching. The conflicts have led to mass displacement, the destruction of cultural heritage, and economic and security implications beyond the region. The international community must work together to address the root causes of these conflicts and find a peaceful resolution to the tensions in the region. This requires a comprehensive approach that addresses the political, economic, and social factors that have contributed to the conflicts. Only then can we hope to bring stability and prosperity to the people of the Middle East and the world.\",\n",
              " 'rewritten_text': \"## Analysis of the Passage:\\n\\nThis passage effectively dissects the themes and motifs of geopolitical tensions in the Middle East, exploring their socio-cultural and global ramifications. The writing is well-structured, clear, and concise, employing vivid imagery and insightful commentary.\\n\\n**Strengths:**\\n\\n* **Comprehensive analysis:** The passage explores various aspects of the conflict, including its impact on displacement, cultural heritage, the global economy, and international security.\\n* **Perceptive commentary:** The author's voice is engaging and insightful, offering unique perspectives on the complex issues at hand.\\n* **Clear structure:** The passage follows a logical structure, beginning with an introduction to the topic, discussing the various impacts, and concluding with a call for international cooperation.\\n* **Vivid imagery:** The passage uses vivid imagery to paint a picture of the conflict and its consequences, making the writing more engaging and impactful.\\n\\n**Areas for Improvement:**\\n\\n* **Lack of sources:** While the writing is well-structured and insightful, it lacks citations or references to support the claims made throughout the text. Adding sources would lend credibility and allow readers to delve deeper into the topic.\\n* **Uncertainties:** Some aspects of the conflict, such as the future outlook and the potential for resolution, are inherently uncertain. Acknowledging these uncertainties and discussing potential solutions could add nuance to the analysis.\\n* **Bias:** The text presents a largely neutral stance, but it could benefit from a more balanced approach that acknowledges different perspectives and viewpoints on the conflict.\\n\\n**Overall:**\\n\\nThis passage provides a well-structured and insightful analysis of the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East. With its clear structure, vivid imagery, and balanced commentary, the text effectively dissects the complex issues at hand. By addressing the areas for improvement, such as the lack of sources and the inclusion of more balanced perspectives, the passage could be even more effective in conveying its message.\",\n",
              " 'chosen_prompt': 'Embark on a journey of intellectual discovery as you dissect the themes and motifs embedded within the following passage, offering perceptive analysis and thought-provoking commentary:',\n",
              " 'rejected_prompt': '## Most Accurate Prompt:\\n\\nWrite an analysis of the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East, focusing on the impact on displacement, cultural heritage, the global economy, and international security. Use vivid imagery and insightful commentary to effectively convey your analysis.',\n",
              " 'score_chosen': 1,\n",
              " 'score_rejected': 0,\n",
              " 'prompt': \"<|im_start|>system\\nFrom the given original and rewritten texts, predict the rewrite prompt used to transform the original text.<|im_end|>\\n<|im_start|>user\\nOriginal: The geopolitical tensions in the Middle East have had significant socio-cultural impacts and far-reaching global ramifications. The region is a hotbed of conflict, with ongoing struggles for power, resources, and political influence. These tensions have resulted in violence, displacement, and instability, which have had profound effects on the people of the region and beyond.\\n\\nOne of the most significant socio-cultural impacts of these tensions is the displacement of millions of people. The conflicts in Syria, Iraq, and Yemen have forced millions of people to flee their homes, creating a massive refugee crisis. Many of these refugees have sought safety in neighboring countries, while others have made the dangerous journey to Europe. This mass displacement has put a significant strain on resources and social services in host countries and has led to cultural and social tensions.\\n\\nThe conflicts in the Middle East have also had a profound impact on the region's cultural heritage. Many historical sites and artifacts have been destroyed or damaged in the fighting, and the region's rich cultural diversity is under threat. The destruction of cultural heritage sites has not only had a devastating impact on the region's cultural identity but has also had economic consequences, as tourism, a significant source of income for many countries in the region, has declined.\\n\\nThe geopolitical tensions in the Middle East have also had significant global ramifications. The region is a major source of oil and gas, and the conflicts have led to disruptions in the global energy market. The rise in oil prices caused by these disruptions has had a ripple effect on the global economy, contributing to inflation and economic instability.\\n\\nFurthermore, the conflicts in the Middle East have had security implications beyond the region. The rise of extremist groups such as ISIS and their spread beyond the region has posed a threat to global security. The conflicts have also led to the proliferation of weapons, including weapons of mass destruction, which poses a significant threat to international peace and security.\\n\\nIn conclusion, the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East are significant and far-reaching. The conflicts have led to mass displacement, the destruction of cultural heritage, and economic and security implications beyond the region. The international community must work together to address the root causes of these conflicts and find a peaceful resolution to the tensions in the region. This requires a comprehensive approach that addresses the political, economic, and social factors that have contributed to the conflicts. Only then can we hope to bring stability and prosperity to the people of the Middle East and the world. ----- Rewritten: ## Analysis of the Passage:\\n\\nThis passage effectively dissects the themes and motifs of geopolitical tensions in the Middle East, exploring their socio-cultural and global ramifications. The writing is well-structured, clear, and concise, employing vivid imagery and insightful commentary.\\n\\n**Strengths:**\\n\\n* **Comprehensive analysis:** The passage explores various aspects of the conflict, including its impact on displacement, cultural heritage, the global economy, and international security.\\n* **Perceptive commentary:** The author's voice is engaging and insightful, offering unique perspectives on the complex issues at hand.\\n* **Clear structure:** The passage follows a logical structure, beginning with an introduction to the topic, discussing the various impacts, and concluding with a call for international cooperation.\\n* **Vivid imagery:** The passage uses vivid imagery to paint a picture of the conflict and its consequences, making the writing more engaging and impactful.\\n\\n**Areas for Improvement:**\\n\\n* **Lack of sources:** While the writing is well-structured and insightful, it lacks citations or references to support the claims made throughout the text. Adding sources would lend credibility and allow readers to delve deeper into the topic.\\n* **Uncertainties:** Some aspects of the conflict, such as the future outlook and the potential for resolution, are inherently uncertain. Acknowledging these uncertainties and discussing potential solutions could add nuance to the analysis.\\n* **Bias:** The text presents a largely neutral stance, but it could benefit from a more balanced approach that acknowledges different perspectives and viewpoints on the conflict.\\n\\n**Overall:**\\n\\nThis passage provides a well-structured and insightful analysis of the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East. With its clear structure, vivid imagery, and balanced commentary, the text effectively dissects the complex issues at hand. By addressing the areas for improvement, such as the lack of sources and the inclusion of more balanced perspectives, the passage could be even more effective in conveying its message. <|im_end|>\\n\",\n",
              " 'chosen': 'Embark on a journey of intellectual discovery as you dissect the themes and motifs embedded within the following passage, offering perceptive analysis and thought-provoking commentary:<|endoftext|>',\n",
              " 'rejected': '## Most Accurate Prompt:\\n\\nWrite an analysis of the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East, focusing on the impact on displacement, cultural heritage, the global economy, and international security. Use vivid imagery and insightful commentary to effectively convey your analysis.<|endoftext|>'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the system message\n",
        "input_text = example[\"prompt\"]\n",
        "\n",
        "# Tokenize input text, ensuring to generate an attention mask this time\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=2000, truncation=True, padding=True)\n",
        "\n",
        "# For open-ended generation, setting pad_token_id explicitly if your model does not have one set\n",
        "if base_model.config.pad_token_id is None:\n",
        "    base_model.config.pad_token_id = base_model.config.eos_token_id\n",
        "\n",
        "# Generate output using the updated inputs\n",
        "outputs = base_model.generate(**inputs, max_length=2000, pad_token_id=base_model.config.pad_token_id)\n",
        "text = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "# Output the model's generated text and the actual rewrite prompt for comparison\n",
        "actual_rewrite_prompt = example['chosen_prompt']\n",
        "print(\"Generated Prompt:\", text)\n",
        "print(\"Actual Rewrite Prompt:\", actual_rewrite_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN8xl6oBSgyI",
        "outputId": "3c0f5578-b466-4f6a-bad1-0ffd5fade691"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Prompt: <|im_start|>system\n",
            "From the given original and rewritten texts, predict the rewrite prompt used to transform the original text.<|im_end|>\n",
            "<|im_start|>user\n",
            "Original: The geopolitical tensions in the Middle East have had significant socio-cultural impacts and far-reaching global ramifications. The region is a hotbed of conflict, with ongoing struggles for power, resources, and political influence. These tensions have resulted in violence, displacement, and instability, which have had profound effects on the people of the region and beyond.\n",
            "\n",
            "One of the most significant socio-cultural impacts of these tensions is the displacement of millions of people. The conflicts in Syria, Iraq, and Yemen have forced millions of people to flee their homes, creating a massive refugee crisis. Many of these refugees have sought safety in neighboring countries, while others have made the dangerous journey to Europe. This mass displacement has put a significant strain on resources and social services in host countries and has led to cultural and social tensions.\n",
            "\n",
            "The conflicts in the Middle East have also had a profound impact on the region's cultural heritage. Many historical sites and artifacts have been destroyed or damaged in the fighting, and the region's rich cultural diversity is under threat. The destruction of cultural heritage sites has not only had a devastating impact on the region's cultural identity but has also had economic consequences, as tourism, a significant source of income for many countries in the region, has declined.\n",
            "\n",
            "The geopolitical tensions in the Middle East have also had significant global ramifications. The region is a major source of oil and gas, and the conflicts have led to disruptions in the global energy market. The rise in oil prices caused by these disruptions has had a ripple effect on the global economy, contributing to inflation and economic instability.\n",
            "\n",
            "Furthermore, the conflicts in the Middle East have had security implications beyond the region. The rise of extremist groups such as ISIS and their spread beyond the region has posed a threat to global security. The conflicts have also led to the proliferation of weapons, including weapons of mass destruction, which poses a significant threat to international peace and security.\n",
            "\n",
            "In conclusion, the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East are significant and far-reaching. The conflicts have led to mass displacement, the destruction of cultural heritage, and economic and security implications beyond the region. The international community must work together to address the root causes of these conflicts and find a peaceful resolution to the tensions in the region. This requires a comprehensive approach that addresses the political, economic, and social factors that have contributed to the conflicts. Only then can we hope to bring stability and prosperity to the people of the Middle East and the world. ----- Rewritten: ## Analysis of the Passage:\n",
            "\n",
            "This passage effectively dissects the themes and motifs of geopolitical tensions in the Middle East, exploring their socio-cultural and global ramifications. The writing is well-structured, clear, and concise, employing vivid imagery and insightful commentary.\n",
            "\n",
            "**Strengths:**\n",
            "\n",
            "* **Comprehensive analysis:** The passage explores various aspects of the conflict, including its impact on displacement, cultural heritage, the global economy, and international security.\n",
            "* **Perceptive commentary:** The author's voice is engaging and insightful, offering unique perspectives on the complex issues at hand.\n",
            "* **Clear structure:** The passage follows a logical structure, beginning with an introduction to the topic, discussing the various impacts, and concluding with a call for international cooperation.\n",
            "* **Vivid imagery:** The passage uses vivid imagery to paint a picture of the conflict and its consequences, making the writing more engaging and impactful.\n",
            "\n",
            "**Areas for Improvement:**\n",
            "\n",
            "* **Lack of sources:** While the writing is well-structured and insightful, it lacks citations or references to support the claims made throughout the text. Adding sources would lend credibility and allow readers to delve deeper into the topic.\n",
            "* **Uncertainties:** Some aspects of the conflict, such as the future outlook and the potential for resolution, are inherently uncertain. Acknowledging these uncertainties and discussing potential solutions could add nuance to the analysis.\n",
            "* **Bias:** The text presents a largely neutral stance, but it could benefit from a more balanced approach that acknowledges different perspectives and viewpoints on the conflict.\n",
            "\n",
            "**Overall:**\n",
            "\n",
            "This passage provides a well-structured and insightful analysis of the socio-cultural impact and global ramifications of the geopolitical tensions in the Middle East. With its clear structure, vivid imagery, and balanced commentary, the text effectively dissects the complex issues at hand. By addressing the areas for improvement, such as the lack of sources and the inclusion of more balanced perspectives, the passage could be even more effective in conveying its message. <|im_end|>\n",
            "<|endoftext|>\n",
            "Actual Rewrite Prompt: Embark on a journey of intellectual discovery as you dissect the themes and motifs embedded within the following passage, offering perceptive analysis and thought-provoking commentary:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_Hrhq2AMszd",
        "outputId": "5253507e-6223-4613-a6f6-7e85bb3ce914"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PhiForCausalLM(\n",
              "  (model): PhiModel(\n",
              "    (embed_tokens): Embedding(51200, 2560)\n",
              "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x PhiDecoderLayer(\n",
              "        (self_attn): PhiAttention(\n",
              "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          (rotary_emb): PhiRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): PhiMLP(\n",
              "          (activation_fn): NewGELUActivation()\n",
              "          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
              "          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
              "        )\n",
              "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://github.com/mlabonne/llm-course/blob/main/Fine_tune_a_Mistral_7b_model_with_DPO.ipynb\n",
        "lora_dropout=0.05\n",
        "lora_alpha=16\n",
        "lora_r=16\n",
        "learning_rate=5e-5\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "def create_peft_config(model):\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        inference_mode=False,\n",
        "        lora_dropout=lora_dropout,\n",
        "        lora_alpha=lora_alpha,\n",
        "        r=lora_r,\n",
        "        bias=\"none\",\n",
        "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"] #, \"o_proj\", \"gate_proj\"]\n",
        "    )\n",
        "\n",
        "    model = prepare_model_for_kbit_training(model)\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "    return model, peft_config\n",
        "\n",
        "model, lora_config = create_peft_config(base_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m2va-v5RsJU",
        "outputId": "f2e5b33d-15a5-4105-aa7f-cfb2da972835"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 7,864,320 || all params: 2,787,548,160 || trainable%: 0.2821231974697076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    learning_rate=learning_rate,\n",
        "\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=1,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=50,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"paged_adamw_32bit\",\n",
        ")"
      ],
      "metadata": {
        "id": "oj48h5ElNRsJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJyYuqdOO4qy",
        "outputId": "7252a6ae-a73c-44c8-ffdf-b1ccf520353b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_content = \"\"\"\n",
        "compute_environment: LOCAL_MACHINE\n",
        "deepspeed_config: {}\n",
        "distributed_type: NO\n",
        "fsdp_config: {}\n",
        "machine_rank: 0\n",
        "main_process_ip: null\n",
        "main_process_port: null\n",
        "main_training_function: main\n",
        "mixed_precision: no\n",
        "num_machines: 1\n",
        "num_processes: 1\n",
        "use_cpu: false\n",
        "\"\"\"\n",
        "\n",
        "config_path = \"/content/my_accelerate_config.yaml\"\n",
        "with open(config_path, \"w\") as config_file:\n",
        "    config_file.write(config_content)\n"
      ],
      "metadata": {
        "id": "gzxQMyfTWlS_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!accelerate launch --config_file /content/my_accelerate_config.yaml"
      ],
      "metadata": {
        "id": "xzjfwrl8Zyhs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    learning_rate=learning_rate,\n",
        "\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=1,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=50,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"paged_adamw_32bit\",\n",
        ")\n",
        "\n",
        "trainer = DPOTrainer(\n",
        "    base_model, # model base_model\n",
        "    ref_model=None,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    peft_config=lora_config,\n",
        "    beta=0.1,\n",
        "    max_prompt_length=2048, #changed from 1024\n",
        "    max_length=1536,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# todo: during training getting these warning:\n",
        "\n",
        "# i guess this is on the base model, need to check. in that case this is fine\n",
        "# UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
        "\n",
        "# seems that this can be ignored:\n",
        "# Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
        "\n",
        "output_dir = os.path.join(output_dir, \"final_checkpoint\")\n",
        "trainer.model.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495,
          "referenced_widgets": [
            "2b25d4f1de4e492d8284c2e20213d0d8",
            "12b96140456540e8967b8305b1191a35",
            "dd0db811870c430a973d504a72448a29",
            "34b2dde48d36494a82a9d97287148f55",
            "ffd9fdf5f5ae4fbd9510ea2994f23bb7",
            "c2c2d5fecc364d3e8bdf8f2fa14dac36",
            "5de61e5259d54a769dab6188e117808d",
            "e5270b9fc8d04e1bac40a96d6d3eb00e",
            "7aa12fc65a1a49d4b9b128d22f8cc50d",
            "59f79a8d0aaa44e0b44ddb2c9c407059",
            "ed4aeafce5ea498f9a466cccc61835c5"
          ]
        },
        "id": "ZSMoVdIINuZr",
        "outputId": "0d811c02-377c-4f6a-94ef-43e4297c2081"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b25d4f1de4e492d8284c2e20213d0d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected a 'cuda' device type for generator but found 'cpu'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5a015a54f8d9>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# todo: during training getting these warning:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1781\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0midx_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_in_batch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0midx_in_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# print(\"Setting seed at epoch\", self.epoch, seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_device_constructors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# NB: This is directly called from C++ in torch/csrc/Device.cpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected a 'cuda' device type for generator but found 'cpu'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(trainer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwigiSZnWHP0",
        "outputId": "bdd8201d-3428-407f-cd47-3878bb121a99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slotnames__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_activate_neftune',\n",
              " '_add_sm_patterns_to_gitignore',\n",
              " '_created_lr_scheduler',\n",
              " '_deactivate_neftune',\n",
              " '_finish_current_push',\n",
              " '_fsdp_qlora_plugin_updates',\n",
              " '_gather_and_numpify',\n",
              " '_get_collator_with_removed_columns',\n",
              " '_get_eval_sampler',\n",
              " '_get_learning_rate',\n",
              " '_get_output_dir',\n",
              " '_get_train_sampler',\n",
              " '_globalstep_last_logged',\n",
              " '_hp_search_setup',\n",
              " '_inner_training_loop',\n",
              " '_issue_warnings_after_load',\n",
              " '_load_best_model',\n",
              " '_load_from_checkpoint',\n",
              " '_load_optimizer_and_scheduler',\n",
              " '_load_rng_state',\n",
              " '_loggers_initialized',\n",
              " '_maybe_log_save_evaluate',\n",
              " '_memory_tracker',\n",
              " '_move_model_to_device',\n",
              " '_nested_gather',\n",
              " '_peft_has_been_casted_to_bf16',\n",
              " '_precomputed_eval_ref_log_probs',\n",
              " '_precomputed_train_ref_log_probs',\n",
              " '_prepare_deepspeed',\n",
              " '_prepare_input',\n",
              " '_prepare_inputs',\n",
              " '_push_from_checkpoint',\n",
              " '_remove_unused_columns',\n",
              " '_report_to_hp_search',\n",
              " '_rotate_checkpoints',\n",
              " '_save',\n",
              " '_save_checkpoint',\n",
              " '_save_optimizer_and_scheduler',\n",
              " '_save_rng_state',\n",
              " '_save_tpu',\n",
              " '_set_signature_columns_if_needed',\n",
              " '_signature_columns',\n",
              " '_sorted_checkpoints',\n",
              " '_stored_metrics',\n",
              " '_tag_names',\n",
              " '_total_loss_scalar',\n",
              " '_train_batch_size',\n",
              " '_trial',\n",
              " '_tune_save_checkpoint',\n",
              " '_wrap_model',\n",
              " 'accelerator',\n",
              " 'add_callback',\n",
              " 'args',\n",
              " 'autocast_smart_context_manager',\n",
              " 'beta',\n",
              " 'build_tokenized_answer',\n",
              " 'call_model_init',\n",
              " 'callback_handler',\n",
              " 'can_return_loss',\n",
              " 'compute_loss',\n",
              " 'compute_loss_context_manager',\n",
              " 'compute_metrics',\n",
              " 'compute_reference_log_probs',\n",
              " 'concatenated_forward',\n",
              " 'concatenated_inputs',\n",
              " 'control',\n",
              " 'create_accelerator_and_postprocess',\n",
              " 'create_model_card',\n",
              " 'create_optimizer',\n",
              " 'create_optimizer_and_scheduler',\n",
              " 'create_scheduler',\n",
              " 'current_flos',\n",
              " 'data_collator',\n",
              " 'dataset_num_proc',\n",
              " 'deepspeed',\n",
              " 'dpo_loss',\n",
              " 'eval_dataset',\n",
              " 'evaluate',\n",
              " 'evaluation_loop',\n",
              " 'floating_point_ops',\n",
              " 'gather_function',\n",
              " 'generate_during_eval',\n",
              " 'get_batch_logps',\n",
              " 'get_batch_loss_metrics',\n",
              " 'get_batch_samples',\n",
              " 'get_decay_parameter_names',\n",
              " 'get_eval_dataloader',\n",
              " 'get_optimizer_cls_and_kwargs',\n",
              " 'get_test_dataloader',\n",
              " 'get_train_dataloader',\n",
              " 'hp_name',\n",
              " 'hp_search_backend',\n",
              " 'hub_model_id',\n",
              " 'hyperparameter_search',\n",
              " 'init_hf_repo',\n",
              " 'ipex_optimize_model',\n",
              " 'is_deepspeed_enabled',\n",
              " 'is_encoder_decoder',\n",
              " 'is_fsdp_enabled',\n",
              " 'is_fsdp_xla_enabled',\n",
              " 'is_fsdp_xla_v2_enabled',\n",
              " 'is_in_train',\n",
              " 'is_local_process_zero',\n",
              " 'is_model_parallel',\n",
              " 'is_peft_model',\n",
              " 'is_world_process_zero',\n",
              " 'label_names',\n",
              " 'label_pad_token_id',\n",
              " 'label_smoother',\n",
              " 'label_smoothing',\n",
              " 'log',\n",
              " 'log_metrics',\n",
              " 'loss_type',\n",
              " 'lr_scheduler',\n",
              " 'max_length',\n",
              " 'max_prompt_length',\n",
              " 'max_target_length',\n",
              " 'metrics_format',\n",
              " 'model',\n",
              " 'model_adapter_name',\n",
              " 'model_init',\n",
              " 'model_wrapped',\n",
              " 'neftune_noise_alpha',\n",
              " 'null_ref_context',\n",
              " 'num_examples',\n",
              " 'num_tokens',\n",
              " 'optimizer',\n",
              " 'padding_value',\n",
              " 'place_model_on_device',\n",
              " 'pop_callback',\n",
              " 'precompute_ref_log_probs',\n",
              " 'predict',\n",
              " 'prediction_loop',\n",
              " 'prediction_step',\n",
              " 'preprocess_logits_for_metrics',\n",
              " 'propagate_args_to_deepspeed',\n",
              " 'push_to_hub',\n",
              " 'ref_adapter_name',\n",
              " 'ref_model',\n",
              " 'reference_free',\n",
              " 'remove_callback',\n",
              " 'save_metrics',\n",
              " 'save_model',\n",
              " 'save_state',\n",
              " 'state',\n",
              " 'store_flos',\n",
              " 'store_metrics',\n",
              " 'tokenize_row',\n",
              " 'tokenizer',\n",
              " 'torch_jit_model_eval',\n",
              " 'train',\n",
              " 'train_dataset',\n",
              " 'training_step',\n",
              " 'truncation_mode',\n",
              " 'use_apex',\n",
              " 'use_cpu_amp',\n",
              " 'use_dpo_data_collator']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(trainer.accelerator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsAFUQREcIVE",
        "outputId": "234738cc-eafc-4e1b-a6e1-0b9abdb900b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_custom_objects',\n",
              " '_dataloaders',\n",
              " '_do_sync',\n",
              " '_get_devices',\n",
              " '_get_named_parameters',\n",
              " '_load_model_state_pre_hook',\n",
              " '_models',\n",
              " '_optimizers',\n",
              " '_prepare_deepspeed',\n",
              " '_prepare_ipex',\n",
              " '_prepare_megatron_lm',\n",
              " '_prepare_msamp',\n",
              " '_prepare_one',\n",
              " '_save_model_state_pre_hook',\n",
              " '_schedulers',\n",
              " 'accumulate',\n",
              " 'autocast',\n",
              " 'autocast_handler',\n",
              " 'backward',\n",
              " 'check_trigger',\n",
              " 'clear',\n",
              " 'clip_grad_norm_',\n",
              " 'clip_grad_value_',\n",
              " 'dataloader_config',\n",
              " 'ddp_handler',\n",
              " 'deepspeed_engine_wrapped',\n",
              " 'device',\n",
              " 'device_placement',\n",
              " 'dispatch_batches',\n",
              " 'distributed_type',\n",
              " 'end_training',\n",
              " 'even_batches',\n",
              " 'flag_tensor',\n",
              " 'fp8_recipe_handler',\n",
              " 'free_memory',\n",
              " 'gather',\n",
              " 'gather_for_metrics',\n",
              " 'get_state_dict',\n",
              " 'get_tracker',\n",
              " 'gradient_accumulation_steps',\n",
              " 'gradient_state',\n",
              " 'init_handler',\n",
              " 'init_trackers',\n",
              " 'is_last_process',\n",
              " 'is_local_main_process',\n",
              " 'is_main_process',\n",
              " 'join_uneven_inputs',\n",
              " 'load_state',\n",
              " 'local_main_process_first',\n",
              " 'local_process_index',\n",
              " 'log',\n",
              " 'log_with',\n",
              " 'logging_dir',\n",
              " 'main_process_first',\n",
              " 'mixed_precision',\n",
              " 'native_amp',\n",
              " 'no_sync',\n",
              " 'num_processes',\n",
              " 'on_last_process',\n",
              " 'on_local_main_process',\n",
              " 'on_local_process',\n",
              " 'on_main_process',\n",
              " 'on_process',\n",
              " 'optimizer_step_was_skipped',\n",
              " 'pad_across_processes',\n",
              " 'prepare',\n",
              " 'prepare_data_loader',\n",
              " 'prepare_model',\n",
              " 'prepare_optimizer',\n",
              " 'prepare_scheduler',\n",
              " 'print',\n",
              " 'process_index',\n",
              " 'project_configuration',\n",
              " 'project_dir',\n",
              " 'reduce',\n",
              " 'register_for_checkpointing',\n",
              " 'register_load_state_pre_hook',\n",
              " 'register_save_state_pre_hook',\n",
              " 'rng_types',\n",
              " 'save',\n",
              " 'save_iteration',\n",
              " 'save_model',\n",
              " 'save_state',\n",
              " 'scaler',\n",
              " 'scaler_handler',\n",
              " 'set_trigger',\n",
              " 'skip_first_batches',\n",
              " 'split_batches',\n",
              " 'split_between_processes',\n",
              " 'state',\n",
              " 'step',\n",
              " 'step_scheduler_with_optimizer',\n",
              " 'sync_gradients',\n",
              " 'trackers',\n",
              " 'trigger_sync_in_backward',\n",
              " 'unscale_gradients',\n",
              " 'unwrap_model',\n",
              " 'use_distributed',\n",
              " 'use_fp16',\n",
              " 'use_seedable_sampler',\n",
              " 'verify_device_map',\n",
              " 'wait_for_everyone']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6l3SOtGScaqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}